{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия по методу наименьших квадратов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a.y.macbookair/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка библиотек\n",
    "import numpy as np # для работы с массивами\n",
    "import pandas as pd # для работы с DataFrame \n",
    "from sklearn import datasets # для импорта данных\n",
    "import seaborn as sns # для визуализации статистических данных\n",
    "import matplotlib.pyplot as plt # для построения графиков\n",
    "\n",
    "# загружаем датасет\n",
    "boston = datasets.load_boston()\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "boston_data['PRICE'] = boston.target\n",
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000e+00 6.3200e-03 6.5750e+00]\n",
      " [1.0000e+00 2.7310e-02 6.4210e+00]\n",
      " [1.0000e+00 2.7290e-02 7.1850e+00]\n",
      " ...\n",
      " [1.0000e+00 6.0760e-02 6.9760e+00]\n",
      " [1.0000e+00 1.0959e-01 6.7940e+00]\n",
      " [1.0000e+00 4.7410e-02 6.0300e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Формируем матрицу  из столбца единиц и факторов и , а также вектор целевой переменной :\n",
    "# составляем матрицу А и вектор целевой переменной\n",
    "CRIM = boston_data['CRIM']\n",
    "RM = boston_data['RM']\n",
    "A = np.column_stack((np.ones(506), CRIM, RM))\n",
    "y = boston_data[['PRICE']]\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 3)\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на размерность матрицы :\n",
    "# проверим размерность\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-29.24471945]\n",
      " [ -0.26491325]\n",
      " [  8.39106825]]\n"
     ]
    }
   ],
   "source": [
    "# Теперь нам ничего не мешает вычислить оценку вектора коэффициентов по выведенной нами формуле МНК:\n",
    "# вычислим OLS-оценку для коэффициентов\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.85733519]\n"
     ]
    }
   ],
   "source": [
    "# Теперь составим прогноз нашей модели:\n",
    "# добавились новые данные:\n",
    "CRIM_new = 0.1\n",
    "RM_new = 8\n",
    "# делаем прогноз типичной стоимости дома\n",
    "PRICE_new = w_hat.iloc[0]+w_hat.iloc[1]*CRIM_new+w_hat.iloc[2]*RM_new\n",
    "print(PRICE_new.values)\n",
    "## [37.85733519]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласитесь, такая запись вычисления оценки стоимости слишком длинная и неудобная, особенно если факторов не два, как у нас, а 200. Более короткий способ сделать прогноз — вычислить скалярное произведение вектора признаков и коэффициентов регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [[37.85733519]]\n"
     ]
    }
   ],
   "source": [
    "# Для удобства дальнейшего использования оформим характеристики нового наблюдения в виде матрицы размером :\n",
    "# короткий способ сделать прогноз\n",
    "new=np.array([[1,CRIM_new,RM_new]])\n",
    "print('prediction:', (new@w_hat).values)\n",
    "## prediction: [[37.85733519]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже знаем, что алгоритм построения модели линейной регрессии по МНК реализован в классе LinearRegression, находящемся в модуле sklearn.linear_model. Для вычисления коэффициентов (обучения модели) нам достаточно передать в метод fit() нашу матрицу с наблюдениями и вектор целевой переменной, а для построения прогноза — вызвать метод predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hat: [[-29.24471945  -0.26491325   8.39106825]]\n",
      "prediction: [[37.85733519]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# создаём модель линейной регрессии\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "# вычисляем коэффициенты регрессии\n",
    "model.fit(A, y)\n",
    "print('w_hat:', model.coef_)\n",
    "new_prediction = model.predict(new)\n",
    "print('prediction:', new_prediction)\n",
    "## w_hat: [[-29.24471945  -0.26491325   8.39106825]]\n",
    "## prediction: [[37.85733519]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь при создании объекта класса LinearRegression мы указали fit_itercept=False, так как в нашей матрице наблюдений уже присутствует столбец с единицами для умножения на свободный член . Его повторное добавление не имеет смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w7/cr51clr955l_16zdnq7qncd40000gn/T/ipykernel_3576/2639739352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# вычислим OLS-оценку для коэффициентов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mw_hat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m## LinAlgError: Singular matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# Давайте посмотрим, что «скажет» Python, если мы попробуем построить модель линейной регрессии на вырожденной матрице \n",
    "# наблюдений, используя классическую формулу линейной регрессии.\n",
    "# создадим вырожденную матрицу А\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1], \n",
    "    [2, 1, 1, 2], \n",
    "    [-2, -1, -1, -2]]\n",
    ").T\n",
    "y = np.array([1, 2, 5, 1])\n",
    "# вычислим OLS-оценку для коэффициентов\n",
    "w_hat=np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat) \n",
    "## LinAlgError: Singular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, мы получили ошибку, говорящую о том, что матрица  — сингулярная (вырожденная), а значит обратить её не получится. Что и требовалось доказать — с математикой всё сходится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hat: [ 6.   -1.25  1.25]\n"
     ]
    }
   ],
   "source": [
    "# Попробуем обучить модель линейной регрессии LinearRegression из модуля sklearn, используя \n",
    "# нашу вырожденную матрицу\n",
    "# создаём модель линейной регрессии\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "# вычисляем коэффициенты регрессии\n",
    "model.fit(A, y)\n",
    "print('w_hat:', model.coef_)\n",
    "## w_hat: [ 6.   -1.25  1.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Никакой ошибки не возникло! Более того, у нас даже получились вполне адекватные оценки коэффициентов линейной регрессии .\n",
    "\n",
    "Но ведь мы только что использовали формулу для вычисления коэффициентов при расчётах вручную и получали ошибку. Как мы могли получить результат, если матрица  вырожденная? Существование обратной матрицы для неё противоречит законам линейной алгебры. Неужели это очередной случай, когда «мнения» математики и Python расходятся?\n",
    "\n",
    "На самом деле, не совсем. Здесь нет никакой магии, ошибки округления или бага. Просто в реализации линейной регрессии в sklearn предусмотрена борьба с плохо определёнными (близкими к вырожденным и вырожденными) матрицами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.069170</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>6.284634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.253994</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>0.702617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>3.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>5.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>0.256510</td>\n",
       "      <td>6.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>6.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>8.780000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CHAS       LSTAT        CRIM          RM\n",
       "count  506.000000  506.000000  506.000000  506.000000\n",
       "mean     0.069170   12.653063    3.613524    6.284634\n",
       "std      0.253994    7.141062    8.601545    0.702617\n",
       "min      0.000000    1.730000    0.006320    3.561000\n",
       "25%      0.000000    6.950000    0.082045    5.885500\n",
       "50%      0.000000   11.360000    0.256510    6.208500\n",
       "75%      0.000000   16.955000    3.677083    6.623500\n",
       "max      1.000000   37.970000   88.976200    8.780000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вновь рассмотрим данные о стоимости жилья в районах Бостона.\n",
    "# На этот раз возьмём четыре признака: CHAS, LSTAT, CRIM и RM.\n",
    "# Для начала посмотрим на статистические характеристики с помощью метода describe():\n",
    "boston_data[['CHAS', 'LSTAT', 'CRIM','RM']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.92052548]\n",
      " [ 3.9975594 ]\n",
      " [-0.58240212]\n",
      " [-0.09739445]\n",
      " [ 5.07554248]]\n"
     ]
    }
   ],
   "source": [
    "# Рассмотрим модель линейной регрессии по МНК без стандартизации. Помним, что необходимо добавить столбец из единиц:\n",
    "# составляем матрицу наблюдений и вектор целевой переменной\n",
    "A = np.column_stack((np.ones(506), boston_data[['CHAS', 'LSTAT', 'CRIM','RM']]))\n",
    "y = boston_data[['PRICE']]\n",
    "# вычисляем OLS-оценку для коэффициентов без стандартизации\n",
    "w_hat=np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помним, что для построения стандартизированной линейной регрессии нам не нужен вектор свободных коэффициентов, а значит и столбец из единиц тоже не понадобится.\n",
    "\n",
    "Сначала центрируем векторы, которые находятся в столбцах матрицы . Для этого вычтем среднее, вычисленное по строкам матрицы  в каждом столбце, с помощью метода mean(). Затем разделим результат на длины центрированных векторов, вычисленных с помощью функции linalg.norm().\n",
    "\n",
    "Примечание. Обратите внимание, что для функции linalg.norm() обязательно необходимо указать параметр axis=0, так как по умолчанию норма считается для всей матрицы, а не для каждого столбца в отдельности. С определением нормы матрицы и тем, как она считается, вы можете ознакомиться в документации к функции norm()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CHAS   LSTAT    CRIM      RM\n",
       "count  506.00  506.00  506.00  506.00\n",
       "mean    -0.00   -0.00    0.00   -0.00\n",
       "std      0.04    0.04    0.04    0.04\n",
       "min     -0.01   -0.07   -0.02   -0.17\n",
       "25%     -0.01   -0.04   -0.02   -0.03\n",
       "50%     -0.01   -0.01   -0.02   -0.00\n",
       "75%     -0.01    0.03    0.00    0.02\n",
       "max      0.16    0.16    0.44    0.16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# составляем матрицу наблюдений без дополнительного столбца из единиц\n",
    "A = boston_data[['CHAS', 'LSTAT', 'CRIM','RM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# стандартизируем векторы в столбцах матрицы A\n",
    "A_cent = A - A.mean()\n",
    "A_st = A_cent/np.linalg.norm(A_cent, axis=0)\n",
    "A_st.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Теперь векторы имеют одинаковые средние значения и стандартные отклонения. \n",
    "# Если вычислить длину каждого из векторов, мы увидим, что они будут равны 1:\n",
    "print(np.linalg.norm(A_st, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для получения стандартизированных коэффициентов нам также понадобится \n",
    "# стандартизация целевой переменной по тому же принципу:\n",
    "\n",
    "# стандартизируем вектор целевой переменной\n",
    "y_cent = y - y.mean()\n",
    "y_st = y_cent/np.linalg.norm(y_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11039956]\n",
      " [-0.45220423]\n",
      " [-0.09108766]\n",
      " [ 0.38774848]]\n"
     ]
    }
   ],
   "source": [
    "# вычислим OLS-оценку для стандартизированных коэффициентов\n",
    "w_hat_st=np.linalg.inv(A_st.T@A_st)@A_st.T@y_st\n",
    "print(w_hat_st.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "процент низкостатусного населения оказывает большее влияние на значение стоимости жилья, чем количество комнат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы проинтерпретировать оценки коэффициентов линейной регрессии (понять, каков будет прирост целевой переменной при изменении фактора на 1 условную единицу), нам достаточно построить линейную регрессию в обычном виде без стандартизации и получить обычный вектор W.\n",
    "\n",
    "Однако, чтобы корректно говорить о том, какой фактор оказывает на прогноз большее влияние, необходимо рассматривать стандартизированную оценку вектора коэффициентов Wst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.091251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.053929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.219247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CHAS     LSTAT      CRIM        RM\n",
       "CHAS   1.000000 -0.053929 -0.055892  0.091251\n",
       "LSTAT -0.053929  1.000000  0.455621 -0.613808\n",
       "CRIM  -0.055892  0.455621  1.000000 -0.219247\n",
       "RM     0.091251 -0.613808 -0.219247  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Давайте поближе взглянем на матрицу Грама для стандартизированных факторов:\n",
    "\n",
    "# матрица Грама\n",
    "A_st.T @ A_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле мы с вами только что вычислили матрицу выборочных корреляций наших исходных факторов. Мы уже сталкивались с ней много раз в разделах по разведывательному анализу данных и машинному обучению, правда, вычисляли её мы с помощью функции Pandas, а теперь научились делать это вручную.\n",
    "\n",
    "Примечание. Матрицу корреляций можно получить только в том случае, если производить стандартизацию признаков как векторы (делить на длину центрированного вектора Xst). Другие способы стандартизации/нормализации признаков не превращают матрицу Грама в матрицу корреляций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### корреляционная матрица\n",
    "корреляционная матрица — это матрица выборочных корреляций между факторами регрессий.\n",
    "\n",
    "корреляцию можно измерять различным способами:\n",
    "\n",
    "        корреляцией Пирсона;\n",
    "        корреляцией Спирмена;\n",
    "        корреляцией Кендалла.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генеральная (истинная) корреляция — это теоретическая величина, которая отражает общую линейную зависимость между случайными величинами и . Забегая вперёд скажем, что данная характеристика является абстрактной и вычисляется для генеральных совокупностей — всех возможных реализаций  и . В природе такой величины не существует, она есть только в теории вероятностей.\n",
    "\n",
    "Выборочная корреляция — это корреляция, вычисленная на ограниченной выборке. Это уже ближе к нашей теме. Выборочная корреляция отражает линейную взаимосвязь между факторами \n",
    "и , реализации которых представлены в выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Сила связи \tЗначение коэффициента корреляции\n",
    "    Отсутствие связи или очень слабая связь \t0…+/- 0.3\n",
    "    Слабая связь \t+/- 0.3…+/- 0.5\n",
    "    Средняя связь \t+/- 0.5…+/- 0.7\n",
    "    Сильная связь \t+/- 0.7…+/- 0.9\n",
    "    Очень сильная или абсолютная связь \t+/- 0.9…+/-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, матрица корреляций — это матрица Грама, составленная для стандартизированных столбцов исходной матрицы наблюдений . Она всегда (в теории) симметричная. На главной диагонали этой матрицы стоят 1, а на местах всех остальных элементов — коэффициенты корреляции между факторами.\n",
    "\n",
    "Если коэффициент корреляции больше 0, то взаимосвязь между факторами прямая (растёт один — растёт второй), в противном случае — обратная (растёт один — падает второй)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 4.7\n",
    "Вычислите коэффициент корреляции между векторами/\n",
    "Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "v = np.array([5, 1, 2])\n",
    "u = np.array([4, 2, 8])\n",
    "\n",
    "print('{:.2f}'.format(np.corrcoef(u, v)[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 4.8\n",
    "Составьте корреляционную матрицу для системы векторов:\n",
    "\n",
    "Для расчёта используйте библиотеку NumPy или Pandas.\n",
    "\n",
    "    1. Чему равен ранг полученной корреляционной матрицы?\n",
    "    2. Чему равен определитель полученной корреляционной матрицы? Ответ округлите до седьмого знака после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 3\n",
      "Determinant: 0.0000005\n",
      "[[1.         0.99925473 0.99983661]\n",
      " [0.99925473 1.         0.99906626]\n",
      " [0.99983661 0.99906626 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "x_1 = np.array([5.1, 1.8, 2.1, 10.3, 12.1, 12.6])\n",
    "x_2 = np.array([10.2, 3.7, 4.1, 20.5, 24.2, 24.1])\n",
    "x_3 = np.array([2.5, 0.9, 1.1, 5.1, 6.1, 6.3])\n",
    "\n",
    "C = np.corrcoef([x_1, x_2, x_3])\n",
    "\n",
    "print('Rank:', np.linalg.matrix_rank(C))\n",
    "print('Determinant: {:.7f}'.format(np.linalg.det(C)))\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### линейная регрессия и метод наименьших квадратов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сразу импортируем необходимые библиотеки для работы с данными:\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У Василия, основателя компании «Газ-Таз-Ваз-Нефть», дела идут в гору: в этом году он открывает 100 новых скважин по добыче газа. Однако в целях оптимизации расходов и для потенциального повышения дохода Василию необходимо оценить, сколько денег будет приносить ему каждая из скважин, а также понять, какие факторы потенциально сильнейшим образом влияют на объём добычи газа. Для этого Василий решил нанять вас как специалиста по построению моделей машинного обучения.\n",
    "\n",
    "Ваша задача — построить регрессионную модель, которая прогнозирует выработку газа на скважине (целевой признак — Prod) на основе остальных характеристик скважины, и проинтерпретировать результаты вашей модели.\n",
    "\n",
    "Для начала в качестве модели будем использовать простую линейную регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Well</th>\n",
       "      <th>Por</th>\n",
       "      <th>Perm</th>\n",
       "      <th>AI</th>\n",
       "      <th>Brittle</th>\n",
       "      <th>TOC</th>\n",
       "      <th>VR</th>\n",
       "      <th>Prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.08</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.80</td>\n",
       "      <td>81.40</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2.31</td>\n",
       "      <td>4165.196191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.22</td>\n",
       "      <td>46.17</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3561.146205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14.02</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.01</td>\n",
       "      <td>72.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4284.348574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.67</td>\n",
       "      <td>6.75</td>\n",
       "      <td>2.63</td>\n",
       "      <td>39.81</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.88</td>\n",
       "      <td>5098.680869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17.52</td>\n",
       "      <td>4.57</td>\n",
       "      <td>3.18</td>\n",
       "      <td>10.94</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3406.132832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Well    Por  Perm    AI  Brittle   TOC    VR         Prod\n",
       "0     1  12.08  2.92  2.80    81.40  1.16  2.31  4165.196191\n",
       "1     2  12.38  3.53  3.22    46.17  0.89  1.88  3561.146205\n",
       "2     3  14.02  2.59  4.01    72.80  0.89  2.72  4284.348574\n",
       "3     4  17.67  6.75  2.63    39.81  1.08  1.88  5098.680869\n",
       "4     5  17.52  4.57  3.18    10.94  1.51  1.90  3406.132832"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/unconv.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 5.1\n",
    "1. Постройте корреляционную матрицу факторов, включив в неё целевой признак. \n",
    "2. Вычислите ранг полученной матрицы корреляций\n",
    "3. Вычислите определитель матрицы корреляций. Ответ округлите до четвёртого знака после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 8\n",
      "Determinant: 0.0007\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "C = data.corr()\n",
    "sns.heatmap(C, annot=True, cmap='seismic');\n",
    "print('Rank:', np.linalg.matrix_rank(C))\n",
    "print('Determinant: {:.4f}'.format(np.linalg.det(C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 5.2\n",
    "Создайте матрицу наблюдений. Обозначьте её за X, а вектор правильных ответов — за y.\n",
    "\n",
    "1. Постройте модель линейной регрессии по методу наименьших квадратов. Для этого используйте матричную формулу NumPy. В качестве ответа укажите полученные оценки коэффициентов модели. Ответ округлите до целого числа.\n",
    "2. Какой признак, согласно найденным целым коэффициентам, является неинформативным и не оказывает влияния на целевую переменную?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept   -1232.0\n",
      "Well            0.0\n",
      "Por           230.0\n",
      "Perm          116.0\n",
      "AI           -365.0\n",
      "Brittle        25.0\n",
      "TOC           -78.0\n",
      "VR            785.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('Prod', axis=1)\n",
    "y = data['Prod'].values\n",
    "index = ['intercept']+list(X.columns)\n",
    "n = X.shape[0]\n",
    "X = np.column_stack((np.ones(n), X))\n",
    "w_hat = np.linalg.inv(X.T@X)@X.T@y\n",
    "print(pd.Series(np.round(w_hat, 0), index=index))\n",
    "\n",
    "# Well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 5.3\n",
    "Далее потренируемся строить предсказание для наблюдений целевой переменной.\n",
    "\n",
    "1. Постройте прогноз выработки газа для скважины с параметрами, указанными ниже. Чему равна абсолютная ошибка построенного вами прогноза для предложенной скважины (в миллионах кубических футов в день). Ответ округлите до целого числа.\n",
    "2. Постройте прогноз выработки газа для всех скважин из обучающего набора данных. Чему равно значение метрики MAPE вашей модели? Ответ приведите в процентах (не указывайте знак процента), округлив его до первого знака после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n"
     ]
    }
   ],
   "source": [
    "x_new = np.array([1, 106, 15.32, 3.71, 3.29, 55.99, 1.35, 2.42])\n",
    "y_new = 4748.315024\n",
    "y_new_pred = x_new @ w_hat\n",
    "print(np.round(np.abs(y_new_pred - y_new), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result MAPE 3.6:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "y_pred = X @ w_hat\n",
    "print('Result MAPE {:.1f}:'.format(mean_absolute_percentage_error(y, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.5\n",
    "Исключите из данных сильно коррелированные между собой факторы. Под сильной корреляцией в данной задаче будем понимать значения, выше . Выбирая, какой из коррелированных факторов оставить, руководствуйтесь коэффициентом корреляции с целевой переменной: оставляйте тот фактор, который больше всего коррелирует с объёмом добычи газа.\n",
    "\n",
    "Также исключите из данных факторы, для которых корреляция с целевой переменной меньше ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept   -1835.0\n",
      "Por           293.0\n",
      "AI           -200.0\n",
      "Brittle        28.0\n",
      "VR            517.0\n",
      "dtype: float64\n",
      "MAPE: 4.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "X = data.drop(['Prod', 'Perm', 'TOC', 'Well'], axis=1)\n",
    "y = data['Prod'].values\n",
    "index = ['intercept']+list(X.columns)\n",
    "n = X.shape[0]\n",
    "X = np.column_stack((np.ones(n), X))\n",
    "w_hat = np.linalg.inv(X.T@X)@X.T@y\n",
    "y_pred = X @ w_hat\n",
    "print(pd.Series(np.round(w_hat, 0), index=index))\n",
    "print(f'MAPE: {mean_absolute_percentage_error(y, y_pred)*100:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полиномиальная регрессия\n",
    "Максимальная степень при переменной  называется степенью полинома.\n",
    "\n",
    "Самый простой пример полинома от одной переменной — парабола. Это полином второй степени.\n",
    "\n",
    "Кстати, отметим важный факт: уравнение прямой также является частным случае полинома первой степени:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4        0.46666667 0.13333333]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 3, -2, 1],\n",
    "    [1, 9, 4, 1]\n",
    "]).T\n",
    "y = np.array([4, 5, 2, 2])\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat) \n",
    "# [2.4        0.46666667 0.13333333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.25799015  2.37672337 -0.1322068  -0.10208147 -0.26501791  0.29722471]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 3, -2, 1, 5, 13, 1],\n",
    "    [3, 4, 5, -2, 4, 11, 3],\n",
    "    [1, 9, 4, 1, 25, 169, 1],\n",
    "    [3, 12, -10, -2, 20, 143, 3],\n",
    "    [9, 16, 25, 4, 16, 121, 9]\n",
    "    \n",
    "]).T\n",
    "y = np.array([4, 5, 2, 2, 6, 8, -1])\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat)\n",
    "## [-2.25799015  2.37672337 -0.1322068  -0.10208147 -0.26501791  0.29722471]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  4]\n",
      " [ 3  4  5]\n",
      " [-2  5  2]\n",
      " [ 1 -2  2]\n",
      " [ 5  4  6]\n",
      " [13 11  8]\n",
      " [ 1  3 -1]]\n"
     ]
    }
   ],
   "source": [
    "# Для начала составим обычную матрицу наблюдений , расположив векторы в столбцах. \n",
    "# Обратите внимание, что вектор из 1 мы не будем добавлять в матрицу \n",
    "# (за нас это сделает генератор полиномиальных признаков):\n",
    "\n",
    "A = np.array([\n",
    "    [1, 3, -2, 1, 5, 13, 1],\n",
    "    [3, 4, 5, -2, 4, 11, 3],\n",
    "    [4, 5, 2, 2, 6, 8, -1],\n",
    "]).T\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Затем импортируем класс PolynomialFeatures из библиотеки sklearn. \n",
    "# Создадим объект этого класса, указав при инициализации степень полинома равной 2. \n",
    "# Также укажем, что нам нужна генерация столбца из 1 (параметр include_bias=True):\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4      5      6      7     8     9\n",
       "0  1.0   1.0   3.0  4.0    1.0    3.0    4.0    9.0  12.0  16.0\n",
       "1  1.0   3.0   4.0  5.0    9.0   12.0   15.0   16.0  20.0  25.0\n",
       "2  1.0  -2.0   5.0  2.0    4.0  -10.0   -4.0   25.0  10.0   4.0\n",
       "3  1.0   1.0  -2.0  2.0    1.0   -2.0    2.0    4.0  -4.0   4.0\n",
       "4  1.0   5.0   4.0  6.0   25.0   20.0   30.0   16.0  24.0  36.0\n",
       "5  1.0  13.0  11.0  8.0  169.0  143.0  104.0  121.0  88.0  64.0\n",
       "6  1.0   1.0   3.0 -1.0    1.0    3.0   -1.0    9.0  -3.0   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Осталось только вызвать метод fit_transform() от имени этого объекта и передать в него нашу матрицу наблюдений A. \n",
    "# Для удобства выведем результат в виде DataFrame:\n",
    "\n",
    "A_poly = poly.fit_transform(A)\n",
    "display(pd.DataFrame(A_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь построим модель полиномиальной регрессии на реальных данных.\n",
    "\n",
    "Возьмём все те же данные о стоимости жилья в районах Бостона. Будем использовать следующие четыре признака: LSTAT, CRIM, PTRATIO и RM. С их помощью мы построим полиномиальную регрессию от первой до пятой степени включительно, а затем сравним результаты по значению средней абсолютной процентной ошибки (MAPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы не дублировать код, объявим функцию polynomial_regression(). Она будет принимать на вход матрицу наблюдений, \n",
    "# вектор ответов и степень полинома, а возвращать матрицу с полиномиальными признаками, \n",
    "# вектор предсказаний и коэффициенты регрессии, найденные по МНК:\n",
    "\n",
    "def polynomial_regression(X, y, k):\n",
    "    poly = PolynomialFeatures(degree=k, include_bias=True)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    w_hat = np.linalg.inv(X_poly.T@X_poly)@X_poly.T@y\n",
    "    y_pred = X_poly @ w_hat\n",
    "    return X_poly, y_pred, w_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем интересующие нас признаки и строим полиномы:\n",
    "\n",
    "A = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    " \n",
    "A_poly, y_pred, w_hat = polynomial_regression(A, y, 1)\n",
    "A_poly2, y_pred2, w_hat2 = polynomial_regression(A, y, 2)\n",
    "A_poly3, y_pred3, w_hat3 = polynomial_regression(A, y, 3)\n",
    "A_poly4, y_pred4, w_hat4 = polynomial_regression(A, y, 4)\n",
    "A_poly5, y_pred5, w_hat5 = polynomial_regression(A, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE для полинома 1-й степени 18.20%\n",
      "MAPE для полинома 2-й степени  13.41%\n",
      "MAPE для полинома 3-й степени  12.93%\n",
      "MAPE для полинома 4-й степени  10.74%\n",
      "MAPE для полинома 5-й степени  213.20%\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на качество построенных регрессий, вычислив метрику:\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    " \n",
    "print('MAPE для полинома 1-й степени {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred)*100))\n",
    "print('MAPE для полинома 2-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred2)*100))\n",
    "print('MAPE для полинома 3-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred3)*100))\n",
    "print('MAPE для полинома 4-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred4)*100))\n",
    "print('MAPE для полинома 5-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred5)*100))\n",
    "## MAPE для полинома 1-й степени 18.20%\n",
    "## MAPE для полинома 2-й степени  13.41%\n",
    "## MAPE для полинома 3-й степени  12.93%\n",
    "## MAPE для полинома 4-й степени  10.74%\n",
    "## MAPE для полинома 5-й степени  5328.16%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полиномиальная регрессия первой степени (линейная регрессия) показывает наименьшее качество предсказания, так как зависимость между факторами и целевым признаком нелинейная. С повышением степени полинома процентная ошибка на обучающей выборке вроде бы падает, однако для полинома пятой степени она резко возрастает и начинает измеряться тысячами процентов. Это означает, что модель вообще не описывает зависимость в исходных данных — её прогноз не имеет никакого отношения к действительности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.103881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5807.624502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-46221.934633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.698434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.877716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40902.697423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PRICE\n",
       "count    126.000000\n",
       "mean      -3.103881\n",
       "std     5807.624502\n",
       "min   -46221.934633\n",
       "25%       -0.698434\n",
       "50%        0.000002\n",
       "75%        1.877716\n",
       "max    40902.697423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# посмотрим на коэффициенты регрессии для полинома пятой степени. Смотреть на каждый из них неудобно, \n",
    "# их слишком много (126, если быть точными), но можно взглянуть на минимум, максимум и среднее:\n",
    "\n",
    "display(pd.DataFrame(w_hat5).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в степенях минимального и максимального коэффициентов явно что-то не так — коэффициенты слишком огромные (исчисляются миллионами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранг корреляционной матрицы: 110\n",
      "Количество факторов: 125\n"
     ]
    }
   ],
   "source": [
    "# Теперь давайте взглянем на корреляционную матрицу для факторов, на которых мы строим полином пятой степени. Корреляцию со столбцом из единиц считать бессмысленно, поэтому мы не будем его рассматривать. Для удобства расчёта матрицы корреляций обернём матрицу  в DataFrame и воспользуемся методом corr():\n",
    "\n",
    "# считаем матрицу корреляций (без столбца из единиц)\n",
    "C = pd.DataFrame(A_poly5[:, 1:]).corr()\n",
    "# считаем ранг корреляционной матрицы\n",
    "print('Ранг корреляционной матрицы:', np.linalg.matrix_rank(C))\n",
    "# считаем количество факторов (не включая столбец из единиц)\n",
    "print('Количество факторов:', A_poly5[:, 1:].shape[1])\n",
    "# Ранг корреляционной матрицы: 110\n",
    "# Количество факторов: 125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы нашли корень проблемы: ранг корреляционной матрицы — 110, в то время как общее количество факторов (не считая единичного столбца) — 125, то есть ранг корреляционной матрицы не максимален. Это значит, что в корреляционной матрице присутствуют единичные корреляции, а в исходной матрице — линейно зависимые столбцы.\n",
    "\n",
    "Как так вышло? На самом деле всё очень просто: в процессе перемножения каких-то из столбцов при создании полинома пятой степени получился такой полиномиальный фактор, который линейно выражается через другие факторы.\n",
    "\n",
    "В результате при вычислении обратной матрицы  у нас получилось деление на число, близкое к 0, а элементы обратной матрицы получились просто огромными. Отсюда и появились явно неверные степени коэффициентов, которые дают далёкий от действительности прогноз, что приводит к отрицательной метрике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранг корреляционной матрицы: 69\n",
      "Количество факторов: 69\n"
     ]
    }
   ],
   "source": [
    "# заметим, что, например, для полинома четвёртой степени ранг матрицы корреляций максимален, \n",
    "# то есть равен количеству факторов (не включая единичный столбец):\n",
    "\n",
    "# считаем матрицу корреляций (без столбца из единиц)\n",
    "C = pd.DataFrame(A_poly4[:, 1:]).corr()\n",
    "# считаем ранг корреляционной матрицы\n",
    "print('Ранг корреляционной матрицы:', np.linalg.matrix_rank(C))\n",
    "# считаем количество факторов (не включая столбец из единиц)\n",
    "print('Количество факторов:', A_poly4[:, 1:].shape[1])\n",
    "## Ранг корреляционной матрицы: 69\n",
    "## Количество факторов: 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-50.890368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>887.339389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6925.309944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.187932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.322230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2305.255303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PRICE\n",
       "count    70.000000\n",
       "mean    -50.890368\n",
       "std     887.339389\n",
       "min   -6925.309944\n",
       "25%      -0.187932\n",
       "50%      -0.000783\n",
       "75%       0.322230\n",
       "max    2305.255303"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Поэтому и коэффициенты регрессии полинома четвёртой степени находятся в адекватных пределах.\n",
    "\n",
    "display(pd.DataFrame(w_hat4).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE для полинома степени 1 — 21.08%, СКО — 4\n",
      "MAPE для полинома степени 2 — 16.44%, СКО — 5\n",
      "MAPE для полинома степени 3 — 15.63%, СКО — 65\n",
      "MAPE для полинома степени 4 — 15.22%, СКО — 135\n",
      "MAPE для полинома степени 5 — 14.71%, СКО — 2479\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, что будет, если использовать для построения полиномиальной регрессии реализацию из библиотеки sklearn. \n",
    "# Создадим функцию polynomial_regression_sk — она будет делать то же самое, что и прошлая функция, но средствами sklearn. Дополнительно будем смотреть также стандартное отклонение (разброс) по коэффициентам регрессии.\n",
    "\n",
    "def polynomial_regression_sk(X, y, k):\n",
    "    poly = PolynomialFeatures(degree=k, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    lr = LinearRegression().fit(X_poly, y)\n",
    "    y_pred = lr.predict(X_poly)\n",
    "    return X_poly, y_pred, lr.coef_\n",
    "\n",
    "A = boston_data[[\"PTRATIO\", \"RM\", \"CRIM\"]]\n",
    "y = boston_data[\"PRICE\"]\n",
    "\n",
    "for k in range(1, 6):\n",
    "    A_poly, y_pred, w_hat = polynomial_regression_sk(A, y, k)\n",
    "    print(\n",
    "        \"MAPE для полинома степени {} — {:.2f}%, СКО — {:.0f}\".format(\n",
    "            k, mean_absolute_percentage_error(y, y_pred)*100, w_hat.std()\n",
    "        )\n",
    "\n",
    "    )\n",
    "## MAPE для полинома степени 1 — 0.68, СКО — 2\n",
    "## MAPE для полинома степени 2 — 0.81, СКО — 5\n",
    "## MAPE для полинома степени 3 — 0.86, СКО — 9\n",
    "## MAPE для полинома степени 4 — 0.91, СКО — 304\n",
    "## MAPE для полинома степени 5 — 0.93, СКО — 17055\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        Модель полиномиальной регрессии — более общий случай линейной регрессии, в котором зависимость целевой переменной от факторов нелинейная.\n",
    "        Поиск коэффициентов полинома аналогичен линейной регрессии — решение неоднородной СЛАУ. \n",
    "        Возможна ситуация, когда какие-то сгенерированные полиномиальные факторы могут линейно выражаться через другие факторы. Тогда ранг корреляционной матрицы будет меньше числа факторов и поиск по классическому МНК-алгоритму не будет успешным.\n",
    "        В sklearn для решения последней проблемы предусмотрена защита — использование сингулярного разложения матрицы . Однако данная защита не решает проблемы неустойчивости коэффициентов регрессии.\n",
    "        Полиномиальная регрессия имеет сильную склонность к переобучению: чем выше степень полинома, тем сложнее модель и выше риск переобучения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 6.4\n",
    "С помощью классического МНК найдите коэффициенты полиномиальной регрессии, если используется полином второй степени и задан фактор x и целевая переменная y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1  2.5 -0. ]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 3, -2, 9],\n",
    "    [1, 9, 4, 81]\n",
    "]).T\n",
    "y = np.array([3, 7, -5, 21])\n",
    "print(np.round(np.linalg.inv(A.T@A)@A.T@y, 1))\n",
    "## [ 0.1  2.5 -0. ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация\n",
    "Регуляризация — это способ уменьшения переобучения моделей машинного обучения путём намеренного увеличения смещения модели для уменьшения её разброса.\n",
    "\n",
    "Цели регуляризации:\n",
    "- предотвратить переобучение модели;\n",
    "- включить в функцию потерь штраф за переобучение;\n",
    "- обеспечить существование обратной матрицы;\n",
    "- не допустить огромных коэффициентов модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель полиномиальной регрессии третьей степени. Будем использовать данные о жилье в Бостоне и возьмём следующие четыре признака: LSTAT, CRIM, PTRATIO и RM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.64 %\n",
      "MAPE на валидационных фолдах: 24.16 %\n"
     ]
    }
   ],
   "source": [
    "# ля оценки качества модели будем использовать кросс-валидацию и сравнивать среднее значение метрики \n",
    "# на тренировочных и валидационных фолдах. Кросс-валидацию организуем с помощью функции cross_validate \n",
    "# из модуля model_selection:\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# В качестве метрики используем среднюю абсолютную процентную ошибку — MAPE.\n",
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    " \n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    " \n",
    "# создаём модель линейной регрессии\n",
    "lr = LinearRegression()\n",
    " \n",
    "# оцениваем качество модели на кросс-валидации, метрика — MAPE\n",
    "cv_results = cross_validate(lr, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))\t\n",
    " \n",
    "## MAPE на тренировочных фолдах: 12.64 %\n",
    "## MAPE на валидационных фолдах: 24.16 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы видим? Даже при, казалось бы, небольшой, третьей степени полинома мы получили переобучение: на тренировочной выборке \\(MAPE=12.64 \\%\\), а вот на тестовой — \\(MAPE=24.16 \\%\\). Показатели качества отличаются практически в два раза, что говорит о высоком разбросе модели. Ещё более удручающий результат мы получим, если воспользуемся полиномом большей степени (при желании вы можете проверить это самостоятельно)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2-регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w7/cr51clr955l_16zdnq7qncd40000gn/T/ipykernel_3576/885709472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# получаем оценку коэффициентов регрессии по МНК\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mw_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m## LinAlgError: Singular matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии по МНК\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat) \n",
    "## LinAlgError: Singular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы ожидаемо получили ошибку, говорящую о том, что матрица вырождена. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6122449  0.29387755 0.5877551 ]\n"
     ]
    }
   ],
   "source": [
    "# Попробуем регуляризацию Тихонова\n",
    "\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# единичная матрица\n",
    "E = np.eye(3)\n",
    "# коэффициент регуляризации \n",
    "alpha = 5\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "w_hat_ridge = np.linalg.inv(A.T@A+alpha*E)@A.T@y\n",
    "print(w_hat_ridge) \n",
    "## [0.6122449  0.29387755 0.5877551 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает! Мы получили вектор весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним, что за реализацию линейной регрессии в sklearn отвечает класс Ridge. Основной параметр модели, на который стоит обратить внимание — alpha, коэффициент регуляризации из формулы Тихонова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6122449  0.29387755 0.5877551 ]\n"
     ]
    }
   ],
   "source": [
    "# Давайте обучим модель для решения нашей последней задачи, а затем проверим коэффициенты регрессии. \n",
    "# Так как мы заранее заложили в матрицу столбец из единиц, то, чтобы получить корректное решение, \n",
    "# параметр fit_intercept следует установить в значение False.\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "ridge = Ridge(alpha=5, fit_intercept=False)\n",
    "ridge.fit(A, y)\n",
    "print(ridge.coef_) \n",
    "## [0.6122449  0.29387755 0.5877551 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили тот же самый результат, что и раньше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, посмотрим, как регуляризация поможет побороть переобучение модели полиномиальной регрессии на наборе данных о домах в Бостоне. Используем те же самые признаки: LSTAT, CRIM, PTRATIO и RM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.54 %\n",
      "MAPE на валидационных фолдах: 17.02 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Воспользуемся моделью полиномиальной регрессии третьей степени с регуляризацией Тихонова \n",
    "# (коэффициент регуляризации возьмём равным 20) и проверим её качество на кросс-валидации по метрике MAPE.\n",
    "\n",
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "# создаём модель линейной регрессии c L2-регуляризацией\n",
    "ridge = Ridge(alpha=20, solver='svd')\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(ridge, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))\n",
    "## MAPE на тренировочных фолдах: 12.54 %\n",
    "## MAPE на валидационных фолдах: 17.02 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам удалось уменьшить ошибку (MAPE) на валидационных фолдах кросс-валидации с 24.16% до 17.02% и сократить разницу в метриках, тем самым уменьшив разброс ответов модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 7.4\n",
    "Вычислите коэффициенты линейной регрессии с -регуляризацией, используя аналитическую формулу Тихонова.\n",
    "Коэффициент регуляизации = 1.\n",
    "\n",
    "В качестве ответа приведите значения полученных коэффициентов линейной регрессии, округлив их до второго знака после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09 -1.71  1.91  0.73]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [5, 9, 4, 3, 5],\n",
    "    [15, 18, 18, 19, 19],\n",
    "    [7, 6, 7, 7, 7]\n",
    "]).T\n",
    "y = np.array([24, 22, 35, 33, 36])\n",
    "E = np.eye(4)\n",
    "# коэффициент регуляризации\n",
    "alpha = 1\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "w_hat_ridge = np.linalg.inv(A.T@A+alpha*E)@A.T@y\n",
    "print(np.round(w_hat_ridge, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1-регуляризация\n",
    "\n",
    "L1-регуляризацией, Lasso (Least Absolute Shrinkage and Selection Operator), называется регуляризация, в которой порядок нормы = 1.\n",
    "\n",
    "Таким образом, в случае L1-регуляризации мы ограничиваем сумму модулей весов модели. Такая величина называется нормой Манхэттена (расстоянием городских кварталов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14925373 0.         0.71921642]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии с помощью L1-регуляризации\n",
    "lasso = Lasso(alpha=0.1, fit_intercept=False)\n",
    "lasso.fit(A, y)\n",
    "print(lasso.coef_)\n",
    "## [1.14925373 0.         0.71921642]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А пока давайте применим -регуляризацию к нашей полиномиальной модели третьей степени, прогнозирующей типичную цену на дома в районах Бостона.\n",
    "\n",
    "Так как метод координатного спуска, который применяется для поиска коэффициентов, является численным, то необходима стандартизация исходных данных, чтобы обеспечить ему сходимость. Возьмём в качестве коэффициента регуляризации и проверим качество полученной модели с помощью кросс-валидации по метрике MAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.44 %\n",
      "MAPE на валидационных фолдах: 16.44 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "# создаём модель линейной регрессии c L1-регуляризацией\n",
    "lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(lasso, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))\n",
    "## MAPE на тренировочных фолдах: 12.44 %\n",
    "## MAPE на валидационных фолдах: 16.44 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что с помощью -регуляризации удалось уменьшить ошибку модели (MAPE) на валидационных фолдах с 24.16% до 16.44% и сократить разницу в метриках на тренировочных и валидационных фолдах даже лучше, чем с этим справилась -регуляризация. Однако на самом деле мы просто удачно выбрали коэффициент регуляризации — при других значениях могли получиться совершенно другие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELASTIC-NET\n",
    "Идея Elastic-Net состоит в том, что мы вводим ограничение как на норму весов порядка = 1, так и на норму порядка = 2\n",
    "\n",
    "Аналитического решения у этой задачи нет, поэтому для её решения в sklearn, как и для модели Lasso, используется координатный спуск.\n",
    "\n",
    "В sklearn эластичная сетка реализована в классе ElasticNet из пакета с линейными моделями — linear_model. За коэффициент отвечает параметр alpha, за коэффициент — l1_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.13492457 0.19525842 0.6237965 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии \n",
    "lasso = ElasticNet(alpha=0.1, l1_ratio=0.2, fit_intercept=False)\n",
    "lasso.fit(A, y)\n",
    "print(lasso.coef_)\n",
    "## [1.13492457 0.19525842 0.6237965 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14379753 0.         0.71993025]\n"
     ]
    }
   ],
   "source": [
    "# получаем оценку коэффициентов регрессии\n",
    "lasso = ElasticNet(alpha=0.1, l1_ratio=0.7, fit_intercept=False)\n",
    "lasso.fit(A, y)\n",
    "print(lasso.coef_)\n",
    "## [1.14379753 0.         0.71993025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14925373 0.         0.71921642]\n"
     ]
    }
   ],
   "source": [
    "# получаем оценку коэффициентов регрессии\n",
    "lasso = ElasticNet(alpha=0.1, l1_ratio=1, fit_intercept=False)\n",
    "lasso.fit(A, y)\n",
    "print(lasso.coef_)\n",
    "## [1.14925373 0.         0.71921642]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В округлениях значения не заметно, однако если присмотреться к коэффициентам более внимательно, можно увидеть, что мы получили в точности те же значения, которые получали для модели Lasso в примере № 2. Неудивительно, ведь мы обнулили влияние -регуляризации, выставив l1_ratio=1. По сути, мы использовали чистую модель Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам осталось только попробовать применить Elastic-Net к данным о недвижимости в Бостоне.\n",
    "\n",
    "Как и для других моделей с регуляризацией, для Elastic-Net также лучше заранее позаботиться о стандартизации данных. В качестве коэффициентов регуляризации возьмём ,  . Качество модели проверим с помощью кросс-валидации на пяти фолдах, метрика — MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.65 %\n",
      "MAPE на валидационных фолдах: 15.70 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "# создаём модель линейной регрессии c L1- и L2-регуляризациями\n",
    "lasso = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000)\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(lasso, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100)) \n",
    "## MAPE на тренировочных фолдах: 12.65 %\n",
    "## MAPE на валидационных фолдах: 15.70 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, Elastic-Net позволил нам уменьшить значение MAPE на валидационных фолдах с 24.16% до 15.7%. Отличный результат! Он получился лучше, чем у моделей Ridge и Lasso, но опять же скажем, что так бывает не всегда."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ На практике при использовании моделей с регуляризацией стоит подбирать значения коэффициентов регуляризации с помощью методов подбора гиперпараметров, которые мы изучали в модуле «ML-7. Оптимизация гиперпараметров модели». Только после подбора гиперпараметров можно сделать вывод, какая из моделей показывает наилучшие результаты для решения конкретной задачи. Надеемся, вы помните, как подбираются гиперпараметры (если нет, освежите знания в модуле ML-7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полиномиальная регрессия и регуляризация: практика\n",
    "Продолжим решать задачу от владельца компании «Газ-Таз-Ваз-Нефть» Василия.\n",
    "\n",
    "Ранее, в юните 5, мы смогли построить модель линейной регрессии, которая прогнозирует выработку газа на скважине. Для этого мы с помощью матрицы корреляций и рассуждений отобрали некоррелированные, значимые для предсказания признаки. Далее мы будем использовать именно их (см. задание 5.5).\n",
    "\n",
    "Мы хотим попробовать улучшить наш результат — метрику MAPE. Для этого воспользуемся моделью полиномиальной регрессии третьей степени. Однако теперь мы знаем, что полиномиальным моделям очень легко переобучиться под исходную выборку, поэтому для контроля качества модели мы будем использовать кросс-валидацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 8.1\n",
    "Сгенерируйте полиномиальные признаки третьего порядка на факторах, которые вы выбрали для обучения моделей. Для этого воспользуйтесь генератором полиномов PolynomialFeatures из библиотеки sklearn. Параметр include_bias установите в значение False.\n",
    "1. Сколько факторов у вас получилось после генерации полиномиальных признаков?\n",
    "2. Обучите модель линейной регрессии из библиотеки sklearn (LinearRegression) на полученных полиномиальных факторах. Оцените среднее значение метрики MAPE, используя кросс-валидацию на пяти фолдах. Чему равны средние значения метрики MAPE на тренировочных и валидационных фолдах? Ответ приведите в процентах (не указывайте знак процента), округлив его до первого знака после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество факторов: 34\n",
      "MAPE на тренировочных фолдах: 1.8\n",
      "MAPE на валидационных фолдах: 2.7\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Prod', 'Perm', 'TOC', 'Well'], axis=1)\n",
    "y = data['Prod'].values\n",
    "\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "print('Количество факторов: {}'.format(X_poly.shape[1]))\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_poly, y)\n",
    "\n",
    "cv_results = cross_validate(lr, X_poly, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.1f}'.format(-cv_results['train_score'].mean() * 100))\n",
    "print('MAPE на валидационных фолдах: {:.1f}'.format(-cv_results['test_score'].mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 8.2\n",
    "Теперь попробуем воспользоваться линейной регрессией с регуляризацией. Для начала возьмём L1-регуляризацию.\n",
    "\n",
    "Обучите модель Lasso из библиотеки sklearn на полученных полиномиальных факторах, предварительно стандартизировав факторы с помощью StandardScaler. Коэффициент регуляризации выставите равным 5.\n",
    "\n",
    "Оцените среднее значение метрики MAPE, используя кросс-валидацию на пяти фолдах.\n",
    "\n",
    "Чему равны средние значения метрики MAPE на тренировочных и валидационных фолдах? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 1.8\n",
      "MAPE на валидационных фолдах: 2.3\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Prod', 'Perm', 'TOC', 'Well'], axis=1)\n",
    "y = data['Prod'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "lasso = Lasso(alpha=5)\n",
    "lasso.fit(X_poly, y)\n",
    "\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(lasso, X_poly, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.1f}'.format(-cv_results['train_score'].mean() * 100))\n",
    "print('MAPE на валидационных фолдах: {:.1f}'.format(-cv_results['test_score'].mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Задание 8.3\n",
    "Проделаем то же самое с L2-регуляризацией.\n",
    "\n",
    "Обучите модель Ridge из библиотеки sklearn на полученных полиномиальных факторах, предварительно стандартизировав факторы с помощью StandardScaler. Коэффициент регуляризации выставите равным 1.\n",
    "\n",
    "Оцените среднее значение метрики MAPE, используя кросс-валидацию на пяти фолдах.\n",
    "\n",
    "Чему равны средние значения метрики MAPE на тренировочных и валидационных фолдах? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 1.8\n",
      "MAPE на валидационных фолдах: 2.7\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Prod', 'Perm', 'TOC', 'Well'], axis=1)\n",
    "y = data['Prod'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_poly, y)\n",
    "\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "\n",
    "cv_results = cross_validate(ridge, X_poly, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.1f}'.format(-cv_results['train_score'].mean() * 100))\n",
    "print('MAPE на валидационных фолдах: {:.1f}'.format(-cv_results['test_score'].mean() * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "214db4c70b1bc942313b235c1b40c372ae21c2ea84de05ae170b614d30d11a2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
