{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация данных. Методы валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    " \n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import tree #деревья решений\n",
    "plt.style.use('seaborn') #стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Прочитаем данные о собранных образцах воды и выведем первые пять строк таблицы:\n",
    "\n",
    "water_data = pd.read_csv('data/water_potability.csv')\n",
    "water_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Невооруженным глазом видно, что большинство столбцов таблицы являются числовыми. Целевой признак — Potability (пригодность для питья): 1 — вода пригодна, 0 — вода непригодна для питья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 14.987790\n",
       "Hardness            0.000000\n",
       "Solids              0.000000\n",
       "Chloramines         0.000000\n",
       "Sulfate            23.840049\n",
       "Conductivity        0.000000\n",
       "Organic_carbon      0.000000\n",
       "Trihalomethanes     4.945055\n",
       "Turbidity           0.000000\n",
       "Potability          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# В данных есть пропуски. Выведем информацию о них в процентном соотношении:\n",
    "\n",
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски медианным значением в признаке зависимости класса воды (Potability). Для этого сгруппируем данные по признаку Potability, посчитаем медиану в каждой группе, а затем отправим результат в метод fillna():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполняем пропуски\n",
    "water_data['ph'] = water_data['ph'].fillna(water_data.groupby('Potability')['ph'].transform('median'))\n",
    "water_data['Sulfate'] = water_data['Sulfate'].fillna(water_data.groupby('Potability')['Sulfate'].transform('median'))\n",
    "water_data['Trihalomethanes'] = water_data['Trihalomethanes'].fillna(water_data.groupby('Potability')['Trihalomethanes'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 0.0\n",
       "Hardness           0.0\n",
       "Solids             0.0\n",
       "Chloramines        0.0\n",
       "Sulfate            0.0\n",
       "Conductivity       0.0\n",
       "Organic_carbon     0.0\n",
       "Trihalomethanes    0.0\n",
       "Turbidity          0.0\n",
       "Potability         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Убедимся в отсутствии пропусков:\n",
    "\n",
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим набор данных на матрицу наблюдений X и вектор правильных ответов y:\n",
    "\n",
    "X = water_data.drop('Potability', axis=1)\n",
    "y = water_data['Potability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод Hold-out\n",
    "Метод hold-out реализован в уже знакомой вам функции train_test_split(). Она предназначена для разбиения исходного набора данных случайным образом на две части в заданных соотношениях.\n",
    "\n",
    "- *arrays — порядковый аргумент с переменным количеством. Набор массивов (это могут быть списки, numpy-массивы, DataFrame), которые подлежат разбиению.\n",
    "- test_size — размер тестовой (валидационной) выборки. Может быть указан в долях. Определяется автоматически, если параметр test_size передан как 1-train_size.\n",
    "- train_size — размер тренировочной выборки. Может быть указан в долях. Определяется автоматически, если параметр test_size передан как 1-test_size.\n",
    "- random_state — число, на основе которого производится генерация случайных чисел.\n",
    "- shuffle — параметр, указывающий, стоит ли перемешивать выборку перед разбиением (по умолчанию True).\n",
    "- stratify — стратифицированное разбиение (о нём мы поговорим в юните по дисбалансу выборки).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим выборку в соотношении 80/20 (test_size=0.2), в качестве значения параметра random_state \n",
    "# по традиции возьмём число 42.\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (656, 9)\n"
     ]
    }
   ],
   "source": [
    "# Проверим размеры полученных выборок:\n",
    "\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "  \n",
    "## Train shape: (2620, 9)\n",
    "## Valid shape: (656, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели будем использовать дерево решений с максимальной глубиной 7, энтропией в качестве критерия информативности, минимальное число объектов в листе дерева — 5.\n",
    "\n",
    "После обучения сделаем предсказание для каждой из выборок и рассчитаем метрику. В качестве метрики для простоты возьмём долю правильных ответов — accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train hold-out accuracy: 0.82\n",
      "Valid hold-out accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик\n",
    "print('Train hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_train, y_train_pred)))\n",
    "print('Valid hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_valid, y_valid_pred))) \n",
    " \n",
    "# Train hold-out accuracy: 0.82\n",
    "# Valid hold-out accuracy: 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же мы используем трёхкомпонентный подход (разбиваем выборку на тренировочную, валидационную и отдельную тестовую), нам понадобится чуть больше кода. К сожалению, в sklearn нет специализированного функционала для такого разбиения.\n",
    "\n",
    "Применим функцию train_test_split() дважды: сначала разобьём исходный набор на тренировочный и валидационный в соотношении 80/20, затем разобьём валидационный набор на валидационный и тестовый в соотношении 50/50. В итоге наша выборка будет разбита в соотношении 80/10/10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем исходную выборку на тренировочную и валидационную в соотношении 80/20\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#разбиваем валидационную выборку на валидационную и тестовую в соотношении 50/50\n",
    "X_valid, X_test, y_valid, y_test = model_selection.train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (328, 9)\n",
      "Test shape: (328, 9)\n"
     ]
    }
   ],
   "source": [
    "# Выводим размерности:\n",
    "\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))\n",
    "\n",
    "## Train shape: (2620, 9)\n",
    "## Valid shape: (328, 9)\n",
    "## Test shape: (328, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод K-Fold\n",
    "Метод k-fold более известен как кросс-валидация (cross validation), или перекрёстный контроль.\n",
    "\n",
    "Пожалуй, это самый популярный метод валидации для оценки качества моделирования, и он используется практически во всех проектах. Эта идея также применяется во многих моделях и методах машинного обучения, например в стекинге.\n",
    "\n",
    "Для больших наборов данных в качестве значения  часто берут 10, то есть выборка разбивается на десять фолдов. В случае маленьких выборок  берут равным 3 или 5.\n",
    "\n",
    "→ Чем больше , тем больше моделей будут обучаться, тем объективнее будет оценка качества, однако тем больше времени займёт процесс валидации.\n",
    "\n",
    "\n",
    "\n",
    "Основные параметры инициализатора KFold:\n",
    "\n",
    "- n_split — число фолдов (число из метода k-fold). По умолчанию — 5.\n",
    "- shuffle — параметр, указывающий, стоит ли перемешивать исходный набор данных перед разбиением. По умолчанию — False.\n",
    "- random_state — число, на основе которого производится генерация случайных чисел, если набор данных будет перемешиваться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В цикле будем:\n",
    "\n",
    "- выделять строки таблицы, относящиеся к текущим тренировочной и валидационной выборкам, в отдельные таблицы;\n",
    "обучать дерево решений;\n",
    "- делать предсказания для текущих тренировочной и валидационной выборок;\n",
    "- рассчитывать метрику accuracy на текущих выборках и заносить её значение в список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "#Создаём список для хранения тренировочных и валидационных метрик\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "#Организуем цикл для кросс-валидации (используем весь набор данных)\n",
    "#train_index — индексы тренировочной выборки\n",
    "#valid_index — индексы валидационной выборки\n",
    "for train_index, valid_index in kf.split(X, y): \n",
    "    #Создаём тренировочную и валидационную выборку, обращаясь по текущим индексам\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    #Обучаем случайный лес на тренировочной выборке\n",
    "    model.fit(X_train, y_train)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    #Рассчитываем метрику и заносим её в список\n",
    "    train_metrics.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    val_metrics.append(metrics.accuracy_score(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8034351145038168, 0.8168637924456315, 0.8027470431133156, 0.8267836703548264, 0.8157191911484166]\n",
      "[0.7957317073170732, 0.7053435114503817, 0.7358778625954199, 0.7282442748091603, 0.732824427480916]\n"
     ]
    }
   ],
   "source": [
    "# Выведем содержимое массивов train_metrics и val_metrics:\n",
    "\n",
    "print(train_metrics)\n",
    "print(val_metrics)\n",
    " \n",
    "## [0.8034351145038168, 0.8168637924456315, 0.8027470431133156, 0.8267836703548264, 0.8157191911484166]\n",
    "## [0.7957317073170732, 0.7053435114503817, 0.7358778625954199, 0.7282442748091603, 0.732824427480916]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле весь приведённый выше код можно значительно сократить, если использовать специальную функцию для кросс-валидации — cross_validate() из модуля model_selection. Она организует процедуру кросс-валидации и расчёт метрик.\n",
    "\n",
    "\n",
    "\n",
    "Основные параметры функции cross_validate():\n",
    "\n",
    "- estimator — модель, качество которой будет проверяться на кросс-валидации.\n",
    "- X — матрица наблюдений.\n",
    "- y — вектор-столбец правильных ответов.\n",
    "- cv — кросс-валидатор из библиотеки sklearn (например, KFold) или количество фолдов, на которые необходимо разбить выборку. По умолчанию используется кросс-валидация на пяти фолдах.\n",
    "- scoring — название метрики в виде строки либо функция для её вычисления ('accuracy', 'precision', 'recall', 'f1' и другие; полный список — в документации к функции).\n",
    "- return_train_score — параметр, указывающий стоит ли возвращать значения метрики, полученные на тренировочных фолдах. По умолчанию — False, то есть метрики считаются только на валидационных фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03542781, 0.06605005, 0.03505898, 0.02851009, 0.03610015]),\n",
       " 'score_time': array([0.00284004, 0.00305796, 0.00225496, 0.00221896, 0.0021677 ]),\n",
       " 'test_score': array([0.79573171, 0.70534351, 0.73587786, 0.72824427, 0.73282443]),\n",
       " 'train_score': array([0.80343511, 0.81686379, 0.80274704, 0.82678367, 0.81571919])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Итоговый код с использованием функции cross_validate() будет выглядеть следующим образом:\n",
    "\n",
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=kf, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод Leave-One-Out\n",
    "Метод leave-one-out (отложенный пример), или поэлементная кросс-валидация — это частный случай кросс-валидации (k-fold), когда размер равняется размеру всей выборки , где — количество примеров (строк в таблице).\n",
    "\n",
    "Идеально подходит для небольших датасетов (менее 100 примеров).\n",
    "\n",
    "Поскольку все доступные данные используются как для обучения, так и для валидации, значения метрик наиболее объективны и надёжны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как датасет у нас довольно большой (более трёх тысяч образцов воды), алгоритм кросс-валидации leave-one-out будет выполняться очень долго. Для экономии времени выполнения кода будем использовать первые 500 наблюдений из исходной таблицы.\n",
    "\n",
    "Примечание. Значение метрики будет рассчитано не для всего набора данных, а только для его части. Если вы захотите рассчитать метрику на всём наборе данных, вместо среза передавайте в функцию таблицу X и столбец y целиком. Но имейте в виду, что код в таком случае может выполняться до нескольких минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём кросс-валидатор LeaveOneOut\n",
    "loo = model_selection.LeaveOneOut()\n",
    " \n",
    "#Считаем метрики на кросс-валидации leave-one-out\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=loo, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    " \n",
    "## Train k-fold mean accuracy: 0.95\n",
    "## Valid k-fold mean accuracy: 0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дисбаланс выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.60989\n",
       "1    0.39011\n",
       "Name: Potability, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Рассмотрим влияние дисбаланса на примере датасета о качестве воды. Взглянем на соотношение классов внутри датасета:\n",
    "\n",
    "display(water_data['Potability'].value_counts(normalize=True))\n",
    "sns.countplot(data=water_data, x='Potability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, около 61 % образцов воды являются непригодными для питья и 39 % являются пригодными. На самом деле, это небольшой дисбаланс классов (61/39). В реальных задачах мы можете столкнуться и с куда более неравномерными соотношениями, например 80/20, 90/10 или даже 99/1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стратифицированное разбиение\n",
    "Для того чтобы снизить влияние дисбаланса классов при разбиении выборки, в наборе данных используется специальный тип разбиения, который называется стратифицированным (stratified). Данное разбиение предполагает, что наблюдения, принадлежащие каждому из классов, гарантированно попадут в каждый из наборов данных в одинаковой пропорции.\n",
    "\n",
    "Давайте на примере рассмотрим, как производить стратифицированное разбиение. Начнём с простого разделения hold-out, которое мы проводим с помощью функции train_test_split(). Для начала проведём обычное случайное разбиение на тренировочную и валидационную выборку (в соотношении 80/20) без стратификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0    0.620229\n",
      "1    0.379771\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.568598\n",
      "1    0.431402\n",
      "Name: Potability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X, y = water_data.drop('Potability', axis=1), water_data['Potability']\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "print('Valid:\\n', y_valid.value_counts(normalize=True), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что соотношения классов в тренировочной выборке — 62/38, а в тестовой — 57/43. Давайте попробуем сбалансировать соотношения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0    0.609924\n",
      "1    0.390076\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.609756\n",
      "1    0.390244\n",
      "Name: Potability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Для стратифицированного разбиения достаточно в функции train_test_split() задать параметр stratify, \n",
    "# в который нужно передать столбец с метками классов, на основе которого будет производиться балансировка. \n",
    "# Это будет столбец с правильными ответами y.\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)\n",
    "print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "print('Valid:\\n', y_valid.value_counts(normalize=True), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь в каждом из наборов данных одинаковые соотношения классов — 61/39. Метрики, полученные при одинаковых соотношениях на выборках, будут более объективными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "----------------------------------------\n",
      "Train:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "----------------------------------------\n",
      "Train:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "Valid:\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: Potability, dtype: float64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Давайте напишем код, который организует стратифицированное k-fold-разбиение на три фолда, и выведем \n",
    "# соотношения классов в каждой из выборок:\n",
    "\n",
    "skf = model_selection.StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "for train_index, valid_index in skf.split(X, y): \n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "    print('Valid:\\n', y_valid.value_counts(normalize=True), sep='')\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор метрики в условиях дисбаланса классов\n",
    "Разобьём выборку на тренировочную и валидационную в соотношении 80/20, используя стратифицированное разбиение, затем обучим модель дерева решений, сделаем предсказание для каждой из выборок и сформируем отчёт о метриках на валидационной выборке с помощью функции classification_report()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83       400\n",
      "           1       0.81      0.55      0.65       256\n",
      "\n",
      "    accuracy                           0.77       656\n",
      "   macro avg       0.78      0.73      0.74       656\n",
      "weighted avg       0.78      0.77      0.76       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик\n",
    "print(metrics.classification_report(y_valid, y_valid_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из отчёта о метриках классификации видно, что для валидационной выборки метрика accuracy составляет 0.77, что, в принципе, является довольно хорошим результатом. Однако если мы посмотрим на метрики recall и f1-score для каждого из классов в отдельности, мы увидим, что метрики для класса 0 значительно выше, чем метрики для класса 1.\n",
    "\n",
    "\n",
    "- Precision для класса 1 составляет 0.81, то есть из всех образцов воды, причисленных моделью к классу пригодных для питья, 81 % действительно являются таковыми.\n",
    "- Recall для класса 1 составляет 0.55, то есть из всех образцов в действительности пригодной для питья воды модель посчитала пригодными лишь 55 %, а остальные 45 % посчитала непригодными.\n",
    "- F1-мера — среднее гармоническое между precision и recall — составила 0.65 для класса 1 и 0.83 — для класса 0. Разница довольно далека от нуля, а значит построенная нами модель больше контролируется на образцах воды, непригодных для питья, и обладает плохой различающей способностью.\n",
    "\n",
    "Однако мы не смогли бы выявить этот факт, если бы ориентировались только на метрику accuracy. Одной из причин такого результата является дисбаланс классов: образцов непригодной для питья попросту больше, чем пригодных для питья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели в условиях дисбаланса классов: Взвешивание\n",
    "Метод заставляет алгоритм обращать большее внимание на объекты менее популярного класса.\n",
    "\n",
    "Для того чтобы задать веса классам, достаточно в инициализаторе модели выставить параметр class_weight='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76       400\n",
      "           1       0.63      0.76      0.69       256\n",
      "\n",
      "    accuracy                           0.73       656\n",
      "   macro avg       0.72      0.73      0.72       656\n",
      "weighted avg       0.74      0.73      0.73       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    class_weight='balanced' #веса классов\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик    \n",
    "print(metrics.classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так гораздо лучше! Обратите внимание на метрики класса 1: значение поднялось с 0.65 до 0.69. Это произошло потому, что мы стали чаще находить образцы пригодной для питья воды, за счёт чего recall увеличился с 0.55 до 0.76 (правда, немного упал precision).\n",
    "\n",
    "Да, метрики для класса 0 стали ниже, и у нас слегка упала метрика accuracy, но таков закон баланса — «чтобы где-то прибыло, надо, чтобы где-то убыло». Пусть в целом картина всё ещё не идеальна, но она заметно улучшилась. Разница метрик между классами значительно сократилась. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели в условиях дисбаланса классов: Выбор порога вероятности. PR кривая\n",
    "PR-кривая (precision-recall curve) — это график зависимости precision от recall при различных значениях порога вероятности.\n",
    "\n",
    "Для построения данного графика мы берём множество различных порогов вероятности (0.1, 0.15, 0.2, …1) и вычисляем метрики precision и recall при разных порогах вероятности.\n",
    "\n",
    "PR-кривая — это графическая метрика качества модели, она комплексно отражает и precision, и recall одновременно (как -мера) и особенно хороша в условиях дисбаланса классов.\n",
    "\n",
    "Качество определяется площадью (PR AUC) под кривой: чем ближе значение площади к 1, тем лучше модель. Идеальная модель — та, у которой площадь равна 1. У такой модели и precision, и recall равны 1. Конечно же, таких моделей не существует в природе.\n",
    "\n",
    "Если площадь под PR-кривой меньше 0.5, модель считается очень слабой (качество её распознавания хуже, чем подбрасывание монетки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём порог вероятности с помощью PR-кривой для нашего примера. Так как порог вероятности является внешним параметром модели, будет правильнее подбирать его на кросс-валидации, организованной на тренировочном наборе данных, а итоговое качество оценивать на отложенной выборке.\n",
    "\n",
    "Пусть мы хотим найти такой порог вероятности, при котором наблюдается максимум метрики F1 для класса 1 (питьевая вода).\n",
    "\n",
    "Перед построением PR-кривой нам необходимо предсказать вероятность принадлежности к классу 1 на валидационных фолдах кросс-валидации.\n",
    "\n",
    "Для предсказания вероятностей используем функцию cross_val_predict(). Данная функция выполняет кросс-валидацию и возвращает предсказания для валидационных фолдов. Если ей передать параметр method='predict_proba', она вернёт предсказанные вероятности для каждого из классов на всех фолдах. Остальные параметры аналогичны параметрам функции cross_validate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [0.24561404, 0.75438596],\n",
       "       [1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.60621762, 0.39378238],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03030303, 0.96969697]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел \n",
    ")\n",
    "#Обучаем модель\n",
    "model.fit(X_train, y_train)\n",
    "#Создаём кросс-валидатор k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    "#Делаем предсказание вероятностей на кросс-валидации\n",
    "y_cv_proba_pred = model_selection.cross_val_predict(model, X_train, y_train, cv=skf, method='predict_proba')\n",
    "y_cv_proba_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это массив из вероятностей для каждого образца воды. Первое число в строке — вероятность того, что данный образец является непригодным для питья, а второе — вероятность того, что данный образец пригоден для питья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделяем столбец с вероятностями для класса 1 \n",
    "y_cv_proba_pred = y_cv_proba_pred[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем построить PR-кривую. Для этого воспользуемся функций precision_recall_curve() из модуля metrics библиотеки sklearn. В данную функцию нужно передать истинные метки классов и предсказанные вероятности. Взамен она вернёт три массива: значения метрик precision и recall, вычисленных на различных порогах вероятности, и сами пороги вероятности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds: [0.         0.02739726 0.02898551 0.05       0.07407407]\n",
      "Precision scores: [0.39007634 0.50050659 0.50357873 0.50437919 0.5043837 ]\n",
      "Recall scores: [1.         0.9667319  0.96379648 0.95792564 0.95694716]\n"
     ]
    }
   ],
   "source": [
    "#Вычисляем координаты PR-кривой\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_train, y_cv_proba_pred)\n",
    "\n",
    "print('Thresholds:', thresholds[:5])\n",
    "print('Precision scores:', precision[:5])\n",
    "print('Recall scores:',recall[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим значение F1 при различных порогах вероятности и найдём такой порог вероятности, при котором она максимальна. Сделать это можно с помощью функции argmax() из модуля numpy — она возвращает индекс максимального элемента массива.\n",
    "\n",
    "Далее построим PR-кривую и отметим на ней точку максимума F1.\n",
    "\n",
    "Примечание. Чтобы вычислить площадь под PR-кривой, используется функция auc() из модуля metrics библиотеки sklearn. В данную функцию нужно передать значения метрик recall и precision при различных порогах вероятности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold = 0.33, F1-Score = 0.69\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Вычисляем F1-score при различных threshold\n",
    "f1_scores = (2 * precision * recall) / (precision + recall)\n",
    "#Определяем индекс максимума\n",
    "idx = np.argmax(f1_scores)\n",
    "print('Best threshold = {:.2f}, F1-Score = {:.2f}'.format(thresholds[idx], f1_scores[idx]))\n",
    " \n",
    "#Строим PR-кривую\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) #фигура + координатная плоскость\n",
    "#Строим линейный график зависимости precision от recall\n",
    "ax.plot(precision, recall, label='Decision Tree PR')\n",
    "#Отмечаем точку максимума F1\n",
    "ax.scatter(precision[idx], recall[idx], marker='o', color='black', label='Best F1 score')\n",
    "#Даём графику название и подписываем оси\n",
    "ax.set_title('Precision-recall curve')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "#Отображаем легенду\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, согласно нашим вычислениям и построенной PR-кривой, максимум (0.69) на кросс-валидации наблюдается при пороге вероятности 0.33.\n",
    "\n",
    "Сделаем предсказание классов с таким порогом для всех объектов из отложенной валидационной выборки и выведем отчёт о метриках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76       400\n",
      "           1       0.62      0.76      0.68       256\n",
      "\n",
      "    accuracy                           0.73       656\n",
      "   macro avg       0.72      0.73      0.72       656\n",
      "weighted avg       0.74      0.73      0.73       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold_opt = thresholds[idx]\n",
    "#Образцы воды, для которых вероятность быть пригодными для питья > threshold_opt, относим к классу 1\n",
    "#В противном случае — к классу 0\n",
    "y_valid_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "y_valid_pred = (y_valid_pred_proba > threshold_opt).astype('int')\n",
    "#Считаем метрики\n",
    "print(metrics.classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, при применении метода подбора вероятности увеличилось значение метрик recall и  для класса 1. Нам удалось сократить разницу метрик между классами и заставить модель практически одинаково хорошо предсказывать классы питьевой и непитьевой воды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели в условиях дисбаланса классов: Сэмплирование\n",
    "Идея очень проста: если у нас мало наблюдений миноритарного класса, следует искусственно увеличить их количество.\n",
    "\n",
    "Простейшая стратегия пересэмплирования — продублировать объекты малого класса. Но это неинтересно и работает довольно плохо. Поэтому были созданы специальные алгоритмы генерации искусственных данных. Самый популярный из таких алгоритмов — алгоритм SMOTE (Synthetic Minority Oversampling Techniques).\n",
    "\n",
    "В основе алгоритма лежит идея генерации некоторого количества искусственных наблюдений, которые были бы «похожи» на наблюдения, имеющиеся в миноритарном классе, но при этом не дублировали их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape before oversampling: (2620, 9)\n",
      "Class balance before oversampling: \n",
      "0    1598\n",
      "1    1022\n",
      "Name: Potability, dtype: int64\n",
      "----------------------------------------\n",
      "Train shape after oversampling: (3196, 9)\n",
      "Class balance after oversampling: \n",
      "0    1598\n",
      "1    1598\n",
      "Name: Potability, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Создадим объект класса SMOTE и вызовем у него метод fit_sample(), передав в него обучающую выборку \n",
    "# (X_train, y_train). Затем выведем количество наблюдений каждого из классов до и после сэмплирования:\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_s, y_train_s = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Train shape before oversampling:', X_train.shape) \n",
    "print('Class balance before oversampling: \\n', y_train.value_counts(), sep='')\n",
    "print('-'*40)\n",
    "print('Train shape after oversampling:', X_train_s.shape)\n",
    "print('Class balance after oversampling: \\n', y_train_s.value_counts(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, размер выборки увеличился с 2620 примеров до 3196, и теперь количество наблюдений каждого из классов одинаково (1598/1598)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       400\n",
      "           1       0.63      0.78      0.69       256\n",
      "\n",
      "    accuracy                           0.73       656\n",
      "   macro avg       0.73      0.74      0.73       656\n",
      "weighted avg       0.75      0.73      0.73       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Попробуем обучить нашу модель на сгенерированных обучающих данных и сделать предсказание \n",
    "# на валидационной выборке (обратите внимание, что с валидационным набором данных мы не производим \n",
    "# никаких преобразований), чтобы рассчитать метрики\n",
    "\n",
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке (с сэмплированием)\n",
    "model.fit(X_train_s, y_train_s)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик    \n",
    "print(metrics.classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам удалось поднять метрики для класса 1 на валидационной выборке и снова найти баланс между метриками классов. Однако мы потеряли в метриках для класса 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обнаружение переобучения\n",
    "Основные способы отследить переобучение:\n",
    "\n",
    "- hold-out-разбиение,\n",
    "- k-fold-валидация и leave-one-out-валидация,\n",
    "- кривые обучения (learning curves)\n",
    "\n",
    "Если качество на валидационной выборке стабильно хуже качества на тренировочной, то это явный признак переобучения.\n",
    "\n",
    "Сначала проверим модель на переобучение с помощью отложенной (hold-out) выборки.\n",
    "\n",
    "Для этого стратифицированно разобьём набор данных на тренировочную и валидационную выборки в соотношении 80/20 и обучим дерево решений с энтропией  в качестве критерия информативности и сбалансированными весами классов без ограничения его глубины и количества объектов в листе. Сделаем предсказание для каждой из выборок и рассчитаем метрику F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 score: 1.00\n",
      "Valid F1 score: 0.67\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "#Создаём модель\n",
    "model_bad = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    class_weight='balanced', #веса классов\n",
    "    random_state=42 #генератор случайных чисел\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model_bad.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model_bad.predict(X_train)\n",
    "y_valid_pred = model_bad.predict(X_valid)\n",
    "#Выводим значения метрик для тренировочной выборки\n",
    "print('Train F1 score: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "#Выводим значения метрик для валидационной выборки\n",
    "print('Valid F1 score: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))\n",
    " \n",
    "# Train F1 score: 1.00\n",
    "# Valid F1 score: 0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "типичная картина переобучения: модель дерева решений полностью адаптировалась под обучающий набор данных, но не нашла общих закономерностей, поэтому результаты на контроле оставляют желать лучшего\n",
    "\n",
    "Проверим гипотезу о наличии переобучения у нашего дерева с помощью кросс-валидации k-fold. Организуем стратифицированную кросс-валидацию на пяти фолдах. На каждом шаге кросс-валидации будем вычислять метрику F1 на тренировочных и валидационных фолдах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.14841795, 0.18673921, 0.06462121, 0.04153514, 0.04177189]),\n",
       " 'score_time': array([0.0106988 , 0.00920391, 0.00436306, 0.00537586, 0.00306511]),\n",
       " 'test_score': array([0.61445783, 0.68421053, 0.62332696, 0.63276836, 0.70119522]),\n",
       " 'train_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold со стратификацией\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model_bad, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=skf, #кросс-валидатор\n",
    "    scoring='f1', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean f1: 1.00\n",
      "Valid k-fold mean f1: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Подсчитаем среднее значение F1 на выборках:\n",
    "\n",
    "print('Train k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "## Train k-fold mean f1: 1.00\n",
    "## Valid k-fold mean f1: 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "необходимо разобраться в причине переобучения модели. Для дерева решений установленный по умолчанию параметр max_depth будет означать, что дерево будет делиться до тех пор, пока не определит правильный класс для каждого объекта из обучающего набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current depth: 27\n"
     ]
    }
   ],
   "source": [
    "# посмотрим на текущую глубину дерева:\n",
    "\n",
    "print('Current depth:', model_bad.get_depth())\n",
    "## Current depth: 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean f1: 0.75\n",
      "Valid k-fold mean f1: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Дерево глубиной 27 — это очень сложная модель. Давайте попробуем её упростить, добавив в дерево решений \n",
    "# ограничение на глубину (max_depth). Пусть максимальная глубина дерева будет равна 7.\n",
    "\n",
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #ограничиваем глубину дерева\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    class_weight='balanced' #веса классов\n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold со стратификацией\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=skf, #кросс-валидатор\n",
    "    scoring='f1', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "\n",
    "\n",
    "## Train k-fold mean f1: 0.75\n",
    "## Valid k-fold mean f1: 0.66\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После ограничения максимальной глубины удалось уменьшить разницу между метриками на тренировочных и валидационных фолдах кросс-валидации.\n",
    "\n",
    "Попробуем добавить ещё одно ограничение к нашему дереву: увеличим количество объектов, которых достаточно для образования листа дерева (min_samples_leaf). По умолчанию этот параметр равен 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean f1: 0.74\n",
      "Valid k-fold mean f1: 0.66\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #ограничиваем глубину дерева\n",
    "    min_samples_leaf=5, #увеличиваем количество объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    class_weight='balanced' #веса классов\n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold со стратификацией\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=skf, #кросс-валидатор\n",
    "    scoring='f1', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "## Train k-fold mean f1: 0.74\n",
    "## Valid k-fold mean f1: 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам удалось ещё немного сократить разницу между метриками на тренировочных и валидационных фолдах и уменьшить переобучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кривая обучения\n",
    "Кривая обучения (learning curve) — это график зависимости некоторой метрики на обучающем (валидационном) наборе данных от количества объектов, которые участвуют в обучении модели.\n",
    "\n",
    "Основное назначение кривых обучения — мониторинг изменения метрики в процессе поступления новых данных. Благодаря этому мы можем найти такой размер данных, начиная с которого обогащение набора данных новыми наблюдениями не приносит значительного эффекта.\n",
    "\n",
    "Благодаря кривым обучения мы можем отслеживать недообучение и переобучение модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "214db4c70b1bc942313b235c1b40c372ae21c2ea84de05ae170b614d30d11a2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
