{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Понижение размерности: PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "рассмотрим работу с PCA на практике. Из датасетов sklearn импортируем датасет MNIST — это данные, основанные на рукописном начертании цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим датасет MNIST\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = fetch_openml(\"mnist_784\")\n",
    "# загрузим признаки в переменную X  \n",
    "X = dataset['data']\n",
    "# загрузим «ответы» в переменную y\n",
    "y = dataset['target']\n",
    "# разделим данные с помощью sklearn на данные для обучения и теста\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# импортируем StandardScaler для стандартизации данных\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# создадим объект класса StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x)\n",
    "# трансформируем датасеты train_x и test_x\n",
    "train_x = scaler.transform(train_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "# импортируем класс PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# создадим объект класса PCA\n",
    "pca = PCA(n_components=300)\n",
    "pca.fit(train_x)\n",
    "# уменьшим размерность данных\n",
    "train_x_pca = pca.transform(train_x)\n",
    "test_x_pca = pca.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим, сколько признаков описывало объект до и после уменьшения размерности. Как мы можем заметить, сначала было 787 признаков, а в конце объект описывают уже 300 главных компонент:\n",
    "\n",
    "print(len(train_x[0]))\n",
    "print(len(train_x_pca[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии, которая на вход будет принимать пиксели изображения и предсказывать, что на нём нарисовано.\n",
    "\n",
    "Напишем функцию, которая будет принимать на вход данные для обучения (матрицу с признаками и правильные ответы) и данные для тестирования модели, а на выходе будет возвращать время, затраченное на обучение модели, и качество модели. В качестве метрики оценивания качества будем использовать метрику accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель, построенная на признаках, полученных после уменьшения размерности. Время обучения 80.03176498413086, метрика модели 0.9261428571428572\n",
      "Модель, построенная на всех исходных признаках. Время обучения 179.18448424339294, метрика модели 0.9187142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# напишем функцию, которая на вход принимает X и y, а возвращает модель и время\n",
    "def get_time_and_accuracy(train_x, train_y, test_x, test_y):\n",
    "    # создадим объект класса LogisticRegression\n",
    "    log_reg_model = LogisticRegression(max_iter=1000)\n",
    "    from time import time\n",
    "    # запишем время с начала эпохи в секундах до обучения модели\n",
    "    start_time = time()\n",
    "    # обучим модель\n",
    "    log_reg_model.fit(train_x, train_y)    \n",
    "    # запишем время с начала эпохи в секундах после обучения\n",
    "    end_time = time()\n",
    "    # подсчитаем время, потраченное на обучение модели\n",
    "    time = end_time-start_time\n",
    "    # предскажем на тестовых данных\n",
    "    y_pred = log_reg_model.predict(test_x)\n",
    "    # посчитаем скор для тестового предсказания\n",
    "    score = accuracy_score(test_y, y_pred)\n",
    "    # вернём время, потраченное на обучение, и качество полученной модели\n",
    "    return time, score\n",
    "\n",
    "model_pca_time, model_pca_acc = get_time_and_accuracy(train_x_pca, train_y, test_x_pca, test_y)\n",
    "print(f\"Модель, построенная на признаках, полученных после уменьшения размерности. Время обучения {model_pca_time}, метрика модели {model_pca_acc}\")\n",
    "# Модель, построенная на признаках, полученных после уменьшения размерности. Время обучения 54.12072825431824, метрика модели 0.9255714285714286\n",
    "\n",
    "model_time, model_acc = get_time_and_accuracy(train_x, train_y, test_x, test_y)\n",
    "print(f\"Модель, построенная на всех исходных признаках. Время обучения {model_time}, метрика модели {model_acc}\")\n",
    "# Модель, построенная на всех исходных признаках. Время обучения 108.04033303260803, метрика модели 0.9187142857142857"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, в данном случае мы потратили на обучение модели в два раза меньше времени, а качество осталось практически таким же.\n",
    "\n",
    "В реальной работе бывает гораздо больше данных и на обучение модели уходит отнюдь не две минуты. Таким образом, применив технику уменьшения размерности, можно существенно сэкономить время."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Понижение размерности: t-SNE\n",
    "t-SNE, в отличие от PCA, использует технику нелинейного снижения размерности данных. Обычно используется снижение размерности многомерного пространства до двух- или трёхмерного с целью дальнейшей визуализации. При преобразовании похожие объекты оказываются рядом, а непохожие — далеко друг от друга."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "214db4c70b1bc942313b235c1b40c372ae21c2ea84de05ae170b614d30d11a2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
